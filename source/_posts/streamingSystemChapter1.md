---
title: 《Streaming System》- 第一章：流计算入门
date: 2000-03-18 19:02:43
tags: 
  - Streaming System
categories: 
  - Streaming System
---

<p></p>
<!-- more -->

## 目录
<!-- toc -->




# 术语：流是什么？

在进一步讨论之前，我想要澄清一件事：什么是流媒体？如今，流媒体这个术语被用来指代许多不同的事物（为了简便，到目前为止我也比较随意地使用了这个词），这可能会导致对流媒体的真正含义或流媒体系统实际能力的误解。因此，我更喜欢对这个术语进行一些明确的定义。

问题的关键在于，许多应该通过描述它们的“本质”（无限数据处理、近似结果等）来描述的内容，已经被俗称为通过流媒体执行引擎等方式进行的操作。这种术语上的不精确使得流媒体的真正含义变得模糊，而且在某些情况下，还会给流媒体系统自身带来一些负担，即它们的能力被视为仅限于历史上被描述为“流媒体”的特征，例如近似或推测结果。

鉴于设计良好的流媒体系统与任何现有的批处理引擎一样有能力（在技术上甚至更有能力）产生正确、一致、可重复的结果，我更喜欢将“流媒体”这个术语限定为一个非常具体的含义：

- 流媒体系统

  一种专门针对无限数据集设计的数据处理引擎。

如果我想谈论低延迟、近似或推测结果，我会使用那些具体的词汇，而不是不精确地称它们为“流媒体”。

在讨论可能遇到的不同类型的数据时，使用准确的术语也是很有用的。在我看来，有两个重要（且正交的）维度定义了给定数据集的形状：基数和构成。

数据集的基数决定了它的大小，基数的最突出的方面是给定数据集是否有限或无限。这里是我用来描述数据集中粗略基数的两个术语：

- 有界数据
  一种有限大小的数据集合。

- 无界数据
  一种无限大小（至少在理论上）的数据集合。

基数很重要，因为无限数据集的无限本质会对处理它们的数据处理框架造成额外的负担。下一节中会详细讨论这个问题。

另一方面，数据集的构成则决定了它的物理表现形式。因此，构成定义了人们可以与所讨论的数据交互的方式。我们将在第6章深入研究构成，但为了让你对事情有一个简要的了解，这里有两个主要的重要构成：

- 表格
  数据集在特定时间点的整体视图。传统上，SQL系统处理表格。

- 流
  数据集随时间演变的逐个元素视图。MapReduce数据处理系统的传承传统上处理流。

我们将在第6、8和9章深入探讨流和表格之间的关系，并且在第8章中，我们还会学习到将它们联系在一起的统一基本概念——时间可变关系。但在那之前，我们主要处理流，因为它是大多数数据处理系统（批处理和流媒体）中管道开发人员直接交互的构成。它也是最自然地体现流处理所独有的挑战的构成。







###  关于流媒体的严重夸大限制

在这个话题上，让我们稍微谈谈流媒体系统可以做什么和不能做什么，重点在于可以。我在本章中最想表达的一件事是，精心设计的流媒体系统可以有多么强大。历史上，流媒体系统一直被限制在提供低延迟、不准确或具有推测性的结果的某种利基市场上，通常与更有能力的批处理系统一起提供最终正确的结果；换句话说，这就是 Lambda 架构。

对于那些不熟悉 Lambda 架构的人，基本思路是同时运行一个流媒体系统和一个批处理系统，两者都执行基本相同的计算。流媒体系统提供低延迟、不准确的结果（要么是因为使用了近似算法，要么是因为流媒体系统本身没有提供正确性），一段时间后，批处理系统会提供正确的输出。最初由 Twitter 的 Nathan Marz（Storm 的创作者）提出，它最终变得非常成功，因为它实际上是一个很棒的想法；流媒体引擎在正确性方面有些令人失望，而批处理引擎与您所期望的一样不稳定，因此 Lambda 让您可以同时拥有两者的优点。不幸的是，维护 Lambda 系统很麻烦：您需要构建、提供和维护两个独立版本的管道，然后还要以某种方式合并两个管道的结果。

作为一位在强一致性流媒体引擎上工作多年的人，我发现 Lambda 架构的整个原则有些不受欢迎。不出所料，当 Jay Kreps 的“质疑 Lambda 架构”文章出现时，我非常喜欢。这是对双模式执行必要性的首批高度可见声明。Kreps 在使用可回放系统（如 Kafka）作为流媒体互联的情况下解决了可重复性问题，甚至提出了 Kappa 架构，这基本上意味着使用一个适合手头工作的精心设计的系统来运行单个管道。我不确定这个观点是否需要自己的希腊字母名称，但我完全支持这个原则。

说实话，我会更进一步。我会认为，精心设计的流媒体系统实际上提供了批处理功能的严格超集。除了效率差异之外，批处理系统就像今天所存在的那样，不需要流媒体系统。对于 Apache Flink 团队将这个想法贯彻到底并构建一个在“批处理”模式下始终是全流媒体的系统，我表示赞赏。

```

                    **批处理和流媒体的效率差异**
                    
我认为这不是流媒体系统的固有限制，而只是迄今为止大多数流媒体系统所做的设计选择的结果。批处理和流媒体之间的效率差异在很大程度上是批处理系统中更高效的捆绑和更有效的洗牌传输的结果。现代批处理系统采取了各种复杂的优化措施，允许使用令人惊讶的适度计算资源实现卓越的吞吐量。没有理由不能将使批处理系统成为效率重量级选手的那些聪明的洞察力类型纳入到为无界数据设计的系统中，为用户提供通常认为是高延迟、高效率的“批处理”处理和低延迟、低效率的“流媒体”处理之间的灵活选择。这实际上是我们在 Google Cloud Dataflow 上所做的，通过在同一统一模型下提供批处理和流媒体运行程序来实现。在我们的情况下，我们使用单独的运行程序，因为我们恰好有两个独立设计的系统，针对其特定的用例进行了优化。从工程角度来看，长期来看，我希望看到我们将两个系统合并成一个系统，同时保持选择适当效率级别的灵活性。但这不是我们今天拥有的东西。而且，由于统一的 Dataflow 模型，这甚至不是严格必要的；因此，它可能永远不会发生。

```

所有这些的推论是，流媒体系统的广泛成熟，加上强大的无界数据处理框架，将在时间上允许将 Lambda 架构降级到大数据历史的古董中，它所属的地方。我相信现在是时候将其变为现实了。因为要做到这一点-也就是在其自己的游戏中击败批处理-您只需要两件事：

- 正确性
  这可以使您与批处理平起平坐。在核心层面上，正确性归结为一致性存储。流媒体系统需要一种方法来随着时间检查点持久状态（Kreps 在他的“为什么本地状态是流处理的基本原语”文章中谈到了这一点），并且必须设计得足够好，以在机器故障的情况下保持一致。几年前，当 Spark Streaming 第一次出现在公共大数据场景中时，它是一束光明中的一束一致性。幸运的是，从那时起，事情已经大大改善，但仍然令人惊讶的是，有多少流媒体系统仍试图在没有强一致状态的情况下运行。

  重申一下-因为这一点很重要：强一致性对于精准一次处理是必需的，这对于任何具有超越批处理系统能力的机会的系统都是必需的。除非您真的不关心结果，否则请避免使用不提供强一致状态的流媒体系统。批处理系统不需要您提前验证它们是否能够产生正确的答案；不要浪费时间在无法达到同样要求的流媒体系统上。

  如果您想了解有关在流媒体系统中实现强一致性所需的内容，我建议您查看 MillWheel、Spark Streaming 和 Flink 快照论文。所有这三个文件都花费了大量时间讨论一致性。Reuven 将在第 5 章深入探讨一致性保证，如果您仍然渴望更多，那么在文献和其他地方有大量关于这个话题的优质信息。

- 关于时间的推理工具

  这可以让您超越批处理。对时间进行推理的良好工具对于处理不同事件时间偏移的无界、无序数据至关重要。越来越多的现代数据集呈现这些特征，而现有的批处理系统（以及许多流媒体系统）缺乏应对它们所施加的困难的必要工具（尽管这正在迅速改变，即使在我写这篇文章时）。我们将在本书的大部分内容中解释和关注该点的各个方面。

  首先，我们对时间域的重要概念有了基本的理解，然后深入探讨了我所说的具有不同事件时间偏移的无界、无序数据。然后，我们将在本章的其余部分中使用批处理和流媒体系统介绍有关有界和无界数据处理的常见方法。
  
  
  
  



###  事件时间与处理时间

要清晰地谈论无限数据处理，需要对所涉及的时间领域有清晰的理解。在任何数据处理系统中，通常有两个我们关心的时间领域：

- 事件时间
  这是事件实际发生的时间。

- 处理时间
  这是事件在系统中被观察到的时间。

并非所有用例都关心事件时间（如果你的用例不关心，那太好了！你的生活就更轻松），但许多用例都关心。例如，随时间表征用户行为、大多数计费应用以及许多类型的异常检测等。

在理想的世界中，事件时间和处理时间总是相等的，事件会在其发生时立即被处理。然而，现实并不是那么友好，事件时间和处理时间之间的偏差不仅非零，而且通常是与底层输入源、执行引擎和硬件特性的特征高度可变的函数。会影响偏差水平的因素包括以下内容：

  - 共享资源限制，例如网络拥塞、网络分区或非专用环境中的共享CPU
  - 软件原因，例如分布式系统逻辑、争用等
  - 数据本身的特征，例如键分布、吞吐量方差或无序方差（即，在整个航班中使用脱机模式的人们将其手机从飞行模式中取出后）

因此，如果在任何现实世界的系统中绘制事件时间和处理时间的进度，通常会得到类似于图1-1中红线的东西。

{%  asset_img  stsy_0101.png  %}  
*图1-1. 时间域映射。x轴表示系统中事件时间的完整性；即，事件时间为X的所有数据的事件时间小于X。y轴表示处理时间的进度；即，数据处理系统在执行时观察到的正常时钟时间。*

在图1-1中，黑色的斜率为1的虚线代表理想状态，即处理时间和事件时间完全相等；红线代表现实。在本例中，系统在处理时间开始时稍有延迟，中间更接近理想，然后在结束时又稍有延迟。乍一看，此图中可见两种类型的偏差，每种偏差在不同的时间域内：

- 处理时间
  理想状态和红线之间的垂直距离是处理时间领域中的延迟。该距离告诉你在事件发生时间时，给定时间的事件的处理时间延迟有多少（在处理时间上）。这是两种偏差中可能更自然和直观的偏差。

- 事件时间
  理想状态和红线之间的水平距离是通道中事件时间偏差的量。它告诉你通道当前距理想状态（在事件时间上）有多远。

在现实中，任何给定时间点的处理时间延迟和事件时间偏差是相同的；它们只是看同一件事情的两种方式。关于延迟/偏差的重要经验教训是：由于事件时间和处理时间之间的总体映射不是静态的（即，延迟/偏差可以任意随时间变化），这意味着如果你关心它们的事件时间（即事件实际发生的时间），那么你不能仅在你的管道观察到它们时分析你的数据。

不幸的是，这是历史上许多为无限数据设计的系统所操作的方式。为了应对无限数据集的无限性，这些系统通常提供一些关于传入数据的窗口的概念。我们稍后会深入讨论窗口，但它基本上意味着将数据集沿时间边界分成有限的数据块。如果你关心正确性并且有兴趣在事件时间的上下文中分析你的数据，你不能使用处理时间定义那些时间边界（即处理时间窗口），因为许多系统这样做；由于分布式系统的固有滞后性、许多类型的输入源的在线/离线性等，处理时间和事件时间之间没有一致的相关性，因此你的事件时间数据中的一些数据将会落入错误的处理时间窗口内，从而使正确性丢失。我们将在接下来的部分以及本书的其余部分中通过许多示例来详细探讨这个问题。

不幸的是，当按事件时间进行窗口化时，情况并不完全乐观。在无限数据的上下文中，无序和可变的偏差会为事件时间窗口带来完整性问题：由于处理时间和事件时间之间缺乏可预测的映射，你如何确定何时观察到给定事件时间X的所有数据？对于许多现实世界的数据源，你根本无法做到这一点。但是，今天使用的绝大多数数据处理系统都依赖于某种完整性的概念，这使它们在应用于无限数据集时处于严重劣势。

我建议，我们应该设计一些工具，允许我们生活在这些复杂数据集所施加的不确定性世界中，而不是试图将无限数据整理成最终变得完整的有限批次的信息。新数据将到达，旧数据可能会被撤回或更新，任何我们构建的系统都应该能够自己应对这些事实，完整性的概念只是特定和适当的用例的方便优化，而不是跨所有用例的语义必要性。

在探讨这种方法可能看起来像什么之前，让我们完成一个有用的背景：常见的数据处理模式。
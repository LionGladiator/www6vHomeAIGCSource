---
title: 训练-并行 
date: 2023-01-06 05:51:54
tags:
  - train
categories:
  - AIGC  
  - train
---

<p></p>
<!-- more -->

## 目录
<!-- toc -->


# 分布式训练 [1]
### 预训练 3D并行
   + 数据并行
   + 模型并行
   + 张量并行

   {% asset_img 'pararllelTraining.jpg' %}



1. [How to Train Really Large Models on Many GPUs? ](https://lilianweng.github.io/posts/2021-09-25-train-large/)


100. [第1章：DeepSpeed-Chat 模型训练实战](https://techdiylife.github.io/big-model-training/deepspeed/deepspeed-chat.html)  Bili 未
      [DeepSpeed-Chat](https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat)

101. [大模型并行训练指南：通俗理解Megatron-DeepSpeed之模型并行与数据并行](https://blog.csdn.net/v_JULY_v/article/details/132462452) 未

102. [全网最全-混合精度训练原理](https://zhuanlan.zhihu.com/p/441591808) 未

103. [全网最全-超大模型+分布式训练架构和经典论文](https://zhuanlan.zhihu.com/p/450854172) 未

104. [分布式训练硬核技术——通信原语](https://zhuanlan.zhihu.com/p/465967735) 未

105. [图解大模型训练之：流水线并行（Pipeline Parallelism），以Gpipe为例](https://zhuanlan.zhihu.com/p/613196255)  系列文章 未
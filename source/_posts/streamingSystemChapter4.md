---
title: 《Streaming System》-第四章：高级窗口
date: 2000-03-14 14:36:25
tags: 
  - Streaming System
categories: 
  - Streaming System
---

<p></p>
<!-- more -->

## 目录
<!-- toc -->



# 何时/何地：处理时间窗口

处理时间窗口对于两个原因都很重要：

- 对于某些用例，例如使用监控（例如，Web服务流量QPS），您希望在观察到它的同时分析传入的数据流，因此处理时间窗口是绝对正确的方法。

- 对于时间事件很重要的用例（例如，分析用户行为趋势、计费、评分等），处理时间窗口绝对不是正确的方法，识别这些情况非常关键。

  

因此，值得深入了解处理时间窗口和事件时间窗口之间的区别，特别是考虑到许多流媒体系统中处理时间窗口的普遍性。

在像本书中所呈现的基于事件时间的窗口作为一级概念的模型中工作时，有两种方法可以使用以实现处理时间窗口：

+ 触发器 Triggers
   忽略事件时间（即使用跨越所有事件时间的全局窗口）并使用触发器在处理时间轴上提供该窗口的快照。
+ 进入时间 Ingress time
   将进入时间分配为数据的事件时间，随后使用常规事件时间窗口。这基本上就是Spark Streaming 1.x之类的东西所做的。

请注意，这两种方法或多或少是等效的，尽管它们在多阶段流水线的情况下略有不同：在触发器版本中，多阶段流水线将独立地在每个阶段切片处理时间“窗口”，因此例如，一个阶段的窗口*N*中的数据可能会在下一个阶段中代替窗口*N*-1或*N*+1;在进入时间版本中，在将数据合并到窗口*N*后，由于通过水印（在Cloud Dataflow情况下）、微批边界（在Spark Streaming情况下）或其他协调因素在引擎级别涉及的进展同步，它将在整个流水线的持续时间内保留在窗口*N*中。



正如我一再指出的那样，处理时间窗口的一个重大缺点是当输入的观察顺序发生变化时，窗口的内容也会发生变化。为了更具体地说明这一点，我们将查看以下三种用例：*事件时间*窗口、通过触发器的*处理时间*窗口和通过进入时间的*处理时间*窗口。

每个将应用于两个不同的输入集（因此总共有六个变体）。两个输入集将是完全相同的事件（即相同的值，在相同的事件时间发生），但是观察顺序不同。第一个集将是我们一直看到的观察顺序，标为白色；第二个则将所有值在处理时间轴上向右移动，如图4-1所示，标为紫色。您可以简单地想象，如果风从东边吹而不是从西边吹（即底层的复杂分布式系统以稍微不同的顺序进行了处理），那么紫色示例就是另一种现实可能发生的方式。

{% dplayer "url=stsy_0401.mp4" %} 

*图4-1。在处理时间中移动输入观察顺序，保持值和事件时间不变*




### **事件时间窗口**

为了建立一个基准，让我们先比较事件时间中固定窗口和基于启发式水印的两种观察顺序。我们将重用示例2-7/图2-10中的早期/晚期代码，以获得图4-2中所示的结果。左边实质上是我们之前看到的；右边是第二个观察顺序的结果。这里需要注意的重要事情是，即使输出的总体形状不同（由于处理时间中的不同观察顺序），*四个窗口的最终结果仍然相同*：14、18、3和12。

{% dplayer "url=stsy_0402.mp4" %} 

*图4-2. 对相同输入的两个不同处理时间顺序的事件时间窗口*






### **触发器的处理时间窗口**

现在，我们将此与刚刚描述的两种处理时间方法进行比较。首先，我们将尝试触发器方法。 实现处理时间“窗口化”的方式有三个方面：|
                        
+ *窗口 Windowing*
   我们使用全局事件时间窗口，因为我们基本上是在使用事件时间窗格模拟处理时间窗口。

+ *触发 Triggering*
   我们在处理时间域中定期触发，基于所需处理时间窗口的大小。

+ *累积 Accumulation*
   我们使用丢弃模式使窗格彼此独立，从而使每个窗格像一个独立的处理时间“窗口”。

相应的代码看起来像示例4-1；请注意，全局窗口是Beam的默认设置，因此没有特定的窗口策略覆盖。

*示例4-1。通过重复，丢弃全局事件时间窗格的处理时间窗口*
```
PCollection<KV<Team, Integer>> totals = input
.apply(Window.triggering(Repeatedly(AlignedDelay(ONE_MINUTE)))
             .discardingFiredPanes())
.apply(Sum.integersPerKey());
```

在流处理运行器上针对输入数据的两种不同排序执行时，结果如图4-3所示。这里有一些有趣的注释：
- 因为我们是通过事件时间窗格模拟处理时间窗口，所以“窗口”在处理时间轴上被划分，这意味着它们的有效宽度在y轴上测量而不是x轴。
- 因为处理时间窗口对输入数据的遇到顺序很敏感，所以每个“窗口”的结果对于两个观察顺序中的每一个都不同，尽管事件本身在每个版本中都在技术上相同时发生。

在左侧，我们得到12、18、18，而在右侧，我们得到7、36、5。

{% dplayer "url=stsy_0403.mp4" %} 

*图4-3. 通过触发器的处理时间“窗口”，针对相同输入数据的两种不同处理时间排序*



### 通过进入时间进行处理时间窗口化 |

最后，让我们看一下通过将输入数据的事件时间映射为它们的进入时间来实现的处理时间窗口。在代码方面，这里有四个值得一提的方面：

- 时间转移  Time-shifting
当元素到达时，它们的事件时间需要被覆盖为进入时间。我们可以通过提供一个新的DoFn来在Beam中实现这一点，该函数使用outputWithTimestamp方法将元素的时间戳设置为当前时间。

- 窗口化 Windowing
返回使用标准事件时间固定窗口。

- 触发器  Triggering
因为进入时间提供了计算完美水印的能力，所以我们可以使用默认的触发器，在这种情况下，当水印通过窗口的结束时隐式地触发一次。

- 累积模式 Accumulation mode
因为我们每个窗口只有一个输出，所以累积模式是无关紧要的。

实际代码可能看起来像Example 4-2中的代码。
*Example 4-2. 通过重复、丢弃全局事件时间窗口的窗格来实现处理时间窗口*

```
PCollection<String> raw = IO.read().apply(ParDo.of(
    new DoFn<String， String>() {
        public void processElement(ProcessContext c) {
        c.outputWithTimestmap(new Instant());
    }
});
PCollection<KV<Team， Integer>> input =
	raw.apply(ParDo.of(new ParseFn());
PCollection<KV<Team， Integer>> totals = input
	.apply(Window.info(FixedWindows.of(TWO_MINUTES))
	.apply(Sum.integersPerKey());
```

在流引擎上执行的效果如图4-4所示。当数据到达时，它们的事件时间会更新以匹配它们的进入时间（即到达时的处理时间），从而向右水平偏移到理想的水印线上。这里有一些关于这个图的有趣注释：

- 与其他处理时间窗口示例一样，当输入顺序改变时，我们会得到不同的结果，尽管输入的值和事件时间保持不变。
- 与其他示例不同，窗口再次在事件时间域中（因此沿着x轴）划分。尽管如此，它们并不是真正的事件时间窗口；我们只是将处理时间映射到事件时间域中，抹掉了每个输入的原始出现记录，并用一个新记录替换它，该记录代表了数据被管道首次观察到的时间。
- 尽管如此，由于水印的存在，触发器的触发仍然会在与先前处理时间示例完全相同的时间发生。

此外，产生的输出值与该示例中的输出值相同，如预期的：左侧为12、18、18，右侧为7、36、5。

- 由于在使用进入时间时可以获得完美的水印，因此实际水印与理想水印匹配，向右上方以1的斜率上升。

{% dplayer "url=stsy_0404.mp4" %} 
*图4-4。通过使用进入时间进行处理时间窗口，在相同输入的两个不同处理时间顺序上*

虽然看到了不同实现处理时间窗口的方法是有趣的，但其中的重要教训自第一章以来一直是我一直在强调的：事件时间窗口是无序的，至少在极限情况下（在输入完成之前，实际窗格可能会有所不同）；处理时间窗口则不是。**如果您关心事件实际发生的时间，您必须使用事件时间窗口，否则您的结果将毫无意义。**现在我将结束我的演讲。



#  何地：会话窗口

处理时间窗口已经够了。现在我们回到了经过验证的事件时间窗口，但现在我们将看看我最喜欢的动态数据驱动窗口之一：*会话*。

会话是一种特殊类型的窗口，可以捕获由不活动间隙终止的数据中的活动期间。它们在数据分析中特别有用，因为它们可以提供特定用户在特定时间段内参与某些活动的活动视图。这允许在会话中的活动之间进行关联，根据会话的长度推断参与水平等等。

从窗口的角度来看，会话有两个特别有趣的方面：

- 它们是*数据驱动的窗口*的例子：窗口的位置和大小是输入数据本身的直接结果，而不是基于一些预定义的时间模式，如固定窗口和滑动窗口。
- 它们也是*不对齐的窗口*的例子。也就是说，窗口并不适用于数据的所有部分，而只适用于特定的数据子集（例如，每个用户）。这与固定窗口和滑动窗口等对齐窗口形成对比，后者通常适用于数据的所有部分。

对于某些用例，可以提前使用共同标识符标记单个会话中的数据（例如，发出带有服务质量信息的心跳脉冲的视频播放器;对于任何给定的观看，所有脉冲都可以提前标记为单个会话ID）。在这种情况下，会话构建起来要容易得多，因为它基本上只是按键分组的一种形式。

然而，在更一般的情况下（即实际会话本身不是提前知道的情况下），会话必须仅从时间内的数据位置构建。处理无序数据时，这变得非常棘手。

图4-5展示了一个示例，其中五个独立记录被分组到具有60分钟间隙超时的会话窗口中。每个记录都开始于其自己的60分钟窗口中（原型会话）。合并重叠的原型会话会产生包含三个和两个记录的两个较大会话窗口。

{% asset_img  stsy_0405.png %}
*图4-5。未合并的原型会话窗口及其结果合并的会话*

提供一般会话支持的关键见解是，完整的会话窗口是一组较小、重叠的窗口的组合，每个窗口包含单个记录，序列中的每个记录与下一个记录之间的不活动间隙不大于预定义的超时时间。因此，即使我们以无序的方式观察会话中的数据，只要到达任何重叠的数据，我们就可以将其合并为最终的会话。

换个角度看，考虑到目前为止我们一直在使用的示例。如果我们指定了一个1分钟的会话超时时间，那么我们期望在图4-6中用虚线黑线划分出两个会话。每个会话都捕获用户的一次活动，会话中的每个事件都至少与会话中的另一个事件相隔不到一分钟。

{% asset_img  stsy_0406.png %}
*图4-6。我们要计算的会话*

为了看到窗口合并如何在遇到事件时随着时间建立这些会话，让我们看看它是如何运作的。我们将使用启用了缩回的早期/准时/后期引发的示例2-10，并将窗口更新为使用一分钟的间隙持续时间超时生成会话。示例4-3说明了这看起来像什么。

*例4-3。使用会话窗口和撤回的早期/准时/延迟触发*   
```
PCollection<KV<Team，Integer>>  totals=input
  .apply（Window.into（Sessions.withGapDuration（ONE_MINUTE）)
                .triggering（
                 AfterWatermark（）
                   .withEarlyFirings（AlignedDelay（ONE_MINUTE））
                   .withLateFirings（AfterCount（1））））
  .apply（Sum.integersPerKey（））;
```

在流引擎上执行，您将获得类似于图4-7所示的内容（请注意，我已经留下了用虚线黑线注释的预期最终会话以供参考）。

{% dplayer "url=stsy_0407.mp4" %}
*图4-7。使用会话窗口和缩回的早期和后期引发的流引擎*

这里有很多事情要做，所以我会向您介绍一些：

- 当遇到值为5的第一个记录时，它被放置在一个单个的原型会话窗口中，该窗口从该记录的事件时间开始，并跨越会话间隙持续时间的宽度；例如，在该数据发生的时间点之后一分钟。我们将来遇到的任何重叠窗口都应该是同一个会话的一部分，并将被合并为这样的窗口。
- 到达的第二个记录是7，由于它与5的窗口不重叠，因此同样被放置在自己的原型会话窗口中。
- 同时，水印已经过去了第一个窗口的末尾，因此值为5的结果在12:06之前实现为准时结果。不久之后，第二个窗口也作为具有值7的推测结果实现，当处理时间达到12:06时。
- 我们接下来观察到一对记录3和4，其原型会话重叠。因此，它们被合并在一起，当12:07的早期触发器触发时，将发出一个值为7的单个窗口。
- 紧随其后的8，它与值为7的两个窗口重叠。因此，它们全部合并在一起，形成一个新的组合会话，值为22。当水印通过该会话的末尾时，它会将值为22的新会话以及以前发出但后来合并到其中的值为7的两个窗口的缩回作为材料化。
- 当9到达时，它与值为5的原型会话和值为22的会话一起形成单个较大的会话，值为36。当水印过去时，36和5和22窗口的缩回都会立即发出。

这是一些非常强大的东西。真正令人惊讶的是，在一个将流处理的维度分解为不同的、可组合的组件的模型中描述这样的东西是多么容易。最终，您可以更专注于有趣的业务逻辑，而不是将数据塑造成可用形式的细枝末节。

如果您不相信我，请查看这篇博客文章，了解如何在Spark Streaming 1.x上手动构建会话（请注意，这不是为了指责他们；Spark的人们已经在其他方面做得足够好，以至于有人确实费心记录构建特定类型的会话支持所需的内容在Spark 1.x之上；您无法对大多数其他系统做出同样的说法）。这非常复杂，他们甚至没有做正确的事件时间会话，也没有提供推测或后期引发或撤销。 [todo 后期引发 是否改成  后期触发 ]


## Draft Here
{% draft %}
参考
[Streaming Systems｜ 第四章：高级窗口](https://zhuanlan.zhihu.com/p/568497474)
{% enddraft %}